{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:teal\"> Deep Reinforcement with $Improvised^1$ Architecture for</span> <span style=\"color:red\">Atari Enduro-v0 </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, concatenate, Permute\n",
    "from keras.layers import Input, Conv2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.activations import  linear\n",
    "\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from rl.agents.dqn import DQNAgent\n",
    "from rl.policy import LinearAnnealedPolicy, EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.core import Processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Enduro-v0 Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x19abbea8630>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANEAAAD8CAYAAADpCEEHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS+QQmSX6fy3r9TBuQNcNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19a961605c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('Enduro-v0')\n",
    "\n",
    "plt.imshow(env.render(mode='rgb_array'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. *Number of possible action*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Possible actoin is : 9\n"
     ]
    }
   ],
   "source": [
    "nb_actions = env.action_space.n\n",
    "print('Total number of Possible actoin is :', nb_actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. *Taking stack of 4 consecutive frames*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape is : (4, 84, 84)\n"
     ]
    }
   ],
   "source": [
    "frame_shape = (84, 84)\n",
    "window_length = 4\n",
    "input_shape = (window_length,) + frame_shape\n",
    "print('Input Shape is :', input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "### Defining class for pre-processing the game_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GameProcess(Processor):\n",
    "    def process_observation(self, observation):\n",
    "        img = Image.fromarray(observation)\n",
    "        img = np.array(img.resize(frame_shape).convert('L'))\n",
    "        return img.astype('uint8')  \n",
    "\n",
    "    def process_state_batch(self, batch):\n",
    "        Processed_batch = batch.astype('float32') / 255.\n",
    "        return Processed_batch\n",
    "\n",
    "    def process_reward(self, reward):\n",
    "        return np.clip(reward, -1., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Improvised Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fire_incept(x, fire=16, intercept=64):\n",
    "    x = Conv2D(fire, (4,4), strides=(2,2))(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    left = Conv2D(intercept, (3,3), padding='same')(x)\n",
    "    left = LeakyReLU(alpha=0.1)(left)\n",
    "    \n",
    "    right = Conv2D(intercept, (5,5), padding='same')(x)\n",
    "    right = LeakyReLU(alpha=0.1)(right)\n",
    "    \n",
    "    x = concatenate([left, right], axis=3)\n",
    "    return x\n",
    "\n",
    "def fire_squeeze(x, fire=16, intercept=64):\n",
    "    x = Conv2D(fire, (1,1))(x)\n",
    "    x = LeakyReLU(alpha=0.1)(x)\n",
    "    \n",
    "    left = Conv2D(intercept, (1,1))(x)\n",
    "    left = LeakyReLU(alpha=0.1)(left)\n",
    "    \n",
    "    right = Conv2D(intercept, (3,3), padding='same')(x)\n",
    "    right = LeakyReLU(alpha=0.1)(right)\n",
    "    \n",
    "    x = concatenate([left, right], axis=3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 4, 84, 84)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "permute_1 (Permute)              (None, 84, 84, 4)     0           input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                (None, 20, 20, 32)    8224        permute_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)        (None, 20, 20, 32)    0           conv2d_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                (None, 9, 9, 64)      32832       leaky_re_lu_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)        (None, 9, 9, 64)      0           conv2d_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 9, 9, 32)      18464       leaky_re_lu_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 9, 9, 32)      51232       leaky_re_lu_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)        (None, 9, 9, 32)      0           conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)        (None, 9, 9, 32)      0           conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 9, 9, 64)      0           leaky_re_lu_3[0][0]              \n",
      "                                                                   leaky_re_lu_4[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 9, 9, 64)      4160        concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)        (None, 9, 9, 64)      0           conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 9, 9, 32)      2080        leaky_re_lu_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 9, 9, 32)      18464       leaky_re_lu_5[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)        (None, 9, 9, 32)      0           conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)        (None, 9, 9, 32)      0           conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 9, 9, 64)      0           leaky_re_lu_6[0][0]              \n",
      "                                                                   leaky_re_lu_7[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 7, 7, 64)      36928       concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)        (None, 7, 7, 64)      0           conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 3136)          0           leaky_re_lu_8[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           1606144     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)        (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 9)             4617        leaky_re_lu_9[0][0]              \n",
      "====================================================================================================\n",
      "Total params: 1,783,145\n",
      "Trainable params: 1,783,145\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "game_input=Input(shape=input_shape)\n",
    "\n",
    "x = Permute((2, 3, 1))(game_input)\n",
    "\n",
    "x = Conv2D(32, (8,8), strides=(4, 4))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "x = fire_incept(x, fire=64, intercept=32)\n",
    "\n",
    "x = fire_squeeze(x, fire=64, intercept=32)\n",
    "\n",
    "x = Conv2D(64, (3,3))(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(512)(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "out = Dense(nb_actions, activation='linear')(x)\n",
    "\n",
    "model_new = Model(game_input, out)\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Configuring the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Allocating memory for experience replay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Memory = SequentialMemory(limit=1000000, window_length=window_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Policy: Epsilon Greedy Exploration\n",
    "<span style=\"color:teal\">*Gradually exploration will be decreased*</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps', value_max=1., value_min=.1, value_test=.05, nb_steps=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Compiling DQN Agent <span style=\"color:Red\">with epsilon-greedy Exploration</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dqn = DQNAgent(model=model_new, nb_actions=nb_actions, policy=Policy, memory=Memory, processor=GameProcess(),\n",
    "               nb_steps_warmup=50000, gamma=.99, target_model_update=10000, train_interval=4, delta_clip=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dqn.compile(Adam(lr=.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:teal\"> Training the model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. For 2M Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "History2M = Dqn.fit(env, nb_steps=2000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Compile the DQN Agent with <span style=\"color:Red\">No Exploration</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dqn = DQNAgent(model=model_new, nb_actions=nb_actions, policy=None, memory=Memory, processor=GameProcess(),\n",
    "               gamma=.99, target_model_update=10000, train_interval=4, delta_clip=1.)\n",
    "\n",
    "Dqn.compile(Adam(lr=0.00025), metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Fit for 1M Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "History3M = Dqn.fit(env, nb_steps=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## <span style=\"color:teal\"> Testing the model </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Resetting the environment for Testing after <span style=\"color:red\">**-  -   2M steps    -  -**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dqn.load_weights('dqn_New_2M.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 160.000, steps: 4441\n",
      "Episode 2: reward: 327.000, steps: 8854\n",
      "Episode 3: reward: 332.000, steps: 8819\n",
      "Episode 4: reward: 355.000, steps: 8882\n",
      "Episode 5: reward: 180.000, steps: 4429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19abd0f3be0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(133)\n",
    "env.seed(133)\n",
    "env.reset()\n",
    "Dqn.test(env, nb_episodes=5, visualize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Again Reseting the environment for Testing after  <span style=\"color:red\">**-  -   3M steps    -  -**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dqn.load_weights('dqn_New_3M.h5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 5 episodes ...\n",
      "Episode 1: reward: 396.000, steps: 8853\n",
      "Episode 2: reward: 148.000, steps: 4442\n",
      "Episode 3: reward: 351.000, steps: 8819\n",
      "Episode 4: reward: 402.000, steps: 8882\n",
      "Episode 5: reward: 421.000, steps: 8866\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(133)\n",
    "env.seed(133)\n",
    "env.reset()\n",
    "test_history = Dqn.test(env, nb_episodes=5, visualize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For 5 Episodes :: Averages Reward : 343.6 with average Steps played for : 7972'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_reward = np.mean(test_history.history['episode_reward'])\n",
    "\n",
    "average_steps = np.mean(test_history.history['nb_steps'])\n",
    "\n",
    "'For 5 Episodes :: Averages Reward : ' + str(average_reward) + ' with average Steps played for : ' + str(int(average_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Trained on: Intel® Xeon® Processor E5, 2.40 GHz, Nvidia Quadro K4200\n",
    "# Bhartendu Thakur, Machine Learning & Computing\n",
    "# https://in.mathworks.com/matlabcentral/profile/authors/10083740-bhartendu?&detail=fileexchange\n",
    "# https://in.linkedin.com/in/bhartendu-thakur-56bb6285"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
